# -*- coding: utf-8 -*-
"""A_ CS235_DT_Implementation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uIZz3X7__ucByoLWhUKwC7FxU1jFpuPB

#Decision Tree on Phishing Website Data
 Cindy Wei

###Read Me

I wrote a binary decision tree (CART) and defined a gini index to calculate the impurity to build out the tree.

I used the Google Developer's [tutorial](https://github.com/random-forests/tutorials/blob/master/decision_tree.ipynb) as a guide and I did not copy & paste their code (with the exception of print_tree).  I've included a subset of the sandbox snipplets (at the bottom) that I did in order to figure out the working code. Because there's too many trials & errors, that's why only a subset is included here. Print_Tree is bit advanced for me to write, thus, that function is taken from the tutorial.

Acknowledgement: Special thanks to Professor Vagelis for the tip to use numpy to manipulate the dataframe.

##Implementation

###Initialization
1.   Import data
2.   Set header into a list
3.   Split into training and test data sets
"""

import pandas as pd
import numpy as np

df = pd.read_excel('kaggle.xlsx', sheet_name='dataset')

#df.head(3)

#df.columns

df.shape

print(len(df))

df.set_index('index', inplace=True)

header =['having_IPhaving_IP_Address', 'URLURL_Length',
       'Shortining_Service', 'having_At_Symbol', 'double_slash_redirecting',
       'Prefix_Suffix', 'having_Sub_Domain', 'SSLfinal_State',
       'Domain_registeration_length', 'Favicon', 'port', 'HTTPS_token',
       'Request_URL', 'URL_of_Anchor', 'Links_in_tags', 'SFH',
       'Submitting_to_email', 'Abnormal_URL', 'Redirect', 'on_mouseover',
       'RightClick', 'popUpWidnow', 'Iframe', 'age_of_domain', 'DNSRecord',
       'web_traffic', 'Page_Rank', 'Google_Index', 'Links_pointing_to_page',
       'Statistical_report', 'Result'  
]

#split the data into training & test 
data_table = pd.DataFrame(np.random.randn(len(df),2)) 
split = np.random.rand(len(data_table)) <= 0.80
train = df[split]
test = df[~split]
print (len(test), len(train))

"""###Define Gini Index"""

# Helper function to check if the variable is a number or not
def is_numeric(value):
  return isinstance(value, int) or isinstance(value, float)

# Count the labels in the Result column
# 1= phish website
# -1 = not a phish website

def count_labels(datarows):
  counts = datarows.iloc[: ,-1].value_counts()
  return counts

"""Gini Index - Lecture deck 05a-supervised, slide 25. <br/>
If a data set D contains examples from n classes, gini(D) is defined as, where Pj is the relative frequency of class j in D
![image.png](data:image/png;base64,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)
"""

# Calculate impurity using the probability of the Pj squared
def gini_index(rows):
  
  labels = count_labels(rows)
  impurity_val = 1
  totalrows = len(rows) 

  label_values = labels.values
  for label_val in label_values:    
    calc = label_val/totalrows
    labl_probability = calc **2      
    impurity_val -= labl_probability
    #print ("label value=", label_val, "/", totalrows)
  #print("impureity ", impurity_val)
  return impurity_val

# Calculate the information gain
# Take uncertainty of parent node and subtract the impurity of its two children nodes
# The probability is the weight, taking the porportion of the true rows vs false rows into account
def info_gain(left, right, uncertainty):
  prob = float(len(left)) / (len(right)+ len(left))
  gain = uncertainty - prob * gini_index(left) - (1-prob) * gini_index(right)
  #print ("uncertain=%f - prob=%f *gini(L)=%f - (1-prob)*gini(R)=%f gain=%f" % (uncertainty, prob, gini_index(left), gini_index(right), gain))
  return gain

"""### Define Split Criteria"""

# Partition the dataset
def partition(rows, evalQ):
  true_rows, false_rows = [], []
  true_rows, false_rows = evalQ.matching(rows)
  #print("true rows: ", true_rows)
  #print("false rows: ", false_rows)
  return true_rows, false_rows

# Separate the data into the positive and negative match
class Split_Criteria:

  # remember the attribute and the value
  def __init__(self, attribute, value):
    self.attribute = attribute    
    self.value = value
    #print ("Set attribute ", attribute, " to ", value)

  # separate the rows by matching the attribute and its condition
  def matching(self, rows):      
    match = rows.loc[rows[self.attribute] == self.value]
    no_match = rows.loc[rows[self.attribute] != self.value]
    #print("matching: ", match)
    #print("no match: ", no_match)    
    return match, no_match

  # to print the attribute and the value
  def __repr__(self):
      return "%s is %s" % (self.attribute, str(self.value))

def find_best_split_criteria(rows):
  best_ID3 = 0        # best information gain
  best_feature = None # track the feature with the best informaiton gain
  current_uncertainty = gini_index(rows)

  #num_columns = len(rows.columns) -1
  np_array = rows.to_numpy()
  num_columns = np_array.shape[1] -1      # shape[0] gives row count and shapes[1] gives column count
  #print("total columns ", num_columns)   # don't count the Results (label) column
    
  for col in range(num_columns):     
    index = header[col]
    #print ("column :", col, "|", index)    
    column_array = np_array[:, header.index(index)]
    unique_values, counts = np.unique(column_array, return_counts=True)
    
    for i in range(len(unique_values)):  # val in unique_values:
    #print (unique_values[i], counts[i]) 
    #for val in unique_values:
      question = Split_Criteria(header[col], counts[i]) # set the current criteria    
      true_rows, false_rows = partition(rows, question)
      
      if len(true_rows) == 0 or len (false_rows) == 0:
        continue
      current_gain = info_gain(true_rows, false_rows, current_uncertainty)
      
      # if found a larger information gain then save the current attribute and value
      if current_gain > best_ID3:
        best_ID3, best_feature = current_gain, question
      
  return best_ID3, best_feature

"""###Define Tree"""

# lead node, then tally the number of labels
class Leaf:
  def __init__(self, rows): 
    self.predictions = count_labels(rows)

# this is the parent nodes or split points
class Decision_Node:
  def __init__ (self, feature, true_branch, false_branch):
    self.feature = feature
    self.true_branch = true_branch
    self.false_branch = false_branch

# constructing the decision tree
def build_tree(rows):

  #print("start fnding criteria")
  ID3, feature = find_best_split_criteria(rows)

  #print("it's a leaf")
  if ID3 == 0: return Leaf(rows)
  
  #print("starting partition")
  t_rows, f_rows = partition(rows, feature)

  #print("starting true branch", t_rows)
  t_branch = build_tree(t_rows)  

  #print("starting fakse branch")
  f_branch = build_tree(f_rows)
  
  return Decision_Node(feature, t_branch, f_branch)

"""### Print Tree
Bit advanced for me to figure out and write, hence taken this print_tree from [github](https://github.com/random-forests/tutorials/blob/master/decision_tree.ipynb)
"""

def print_tree(node, spacing=""):
    """World's most elegant tree printing function."""

    # Base case: we've reached a leaf
    if isinstance(node, Leaf):
        print (spacing + "Predict", node.predictions)
        return

    # Print the question at this node
    print (spacing + str(node.feature))

    # Call this function recursively on the true branch
    print (spacing + '--> True:')
    print_tree(node.true_branch, spacing + "  ")

    # Call this function recursively on the false branch
    print (spacing + '--> False:')
    print_tree(node.false_branch, spacing + "  ")

"""### Train Data"""

# take the training set and feed it into the classifer
train_tree = build_tree(train)

#print_tree(train_tree)

"""###Test Data"""

# take the test data and feed it into the classifer
test_tree = build_tree(test)

#print_tree(test_tree)

"""###Sandbox Area
This is used to figure out code snipplets
"""

rows = test 
  np_array = rows.to_numpy()
  num_columns = np_array.shape[1] -2
  print("total columns ", num_columns)

for col in range(num_columns):     
    index = header[col]
    print (index)

abc = df[df.columns[0:10]].iloc[: 20]

# Partition the dataset
def partition(rows, question):
  true_rows, false_rows = [], []
  for j in header: # for each column
    for i in rows: # for each row
      if question.matching(rows.iloc[i, j]):
        true_rows.append(rows.iloc[i])
      else:
        false_rows.append(rows.iloc[i])
    return true_rows, false_rows

dset = df
origDS = pd.DataFrame(np.random.randn(33,2))
split = np.random.rand(len(origDS)) < 0.8
train = dset[split]
test = dset[~split]
print (len(test), len(train))

# Count the labels
def labels(rs):
  counts = rs.iloc[: ,-1].value_counts()
  return counts

my_split_alg(df)

import numpy as np
#p = (training_data[0])
p = df.to_numpy()
v = p.shape[0]
print(v)
'''
index = header[0]
sz = p[:, header.index(index)]
print (sz)

unique_values, counts = np.unique(sz, return_counts=True)
for i in range(len(unique_values)):# val in unique_values:
  print (unique_values[i], counts[i]) 
print (index, unique, counts)
'''#df.shape

len(df.index)

def sb_partition(rows, question):
  true_rows, false_rows = [], []
  true_rows, false_rows = question.matching(rows)  
  return true_rows, false_rows

class SB_Split_Criteria:

  def __init__(self, attribute, value):
    self.attribute = attribute    
    self.value = value
    print ("Set attribute ", attribute, " to ", value)

  def matching(self, rows):   
    #print(abc.loc[abc[search] == val])
    #print("start matching")
    match = rows.loc[rows[self.attribute] == self.value]
    no_match = rows.loc[rows[self.attribute] != self.value]    
    return match, no_match

  def __repr__(self):
      return "%s is %s" % (self.attribute, str(self.value))

def find_greedy_attribute(rows):
  best_ID3 = 0        # best information gain
  best_feature = None # track the feature with the best informaiton gain
  #attrDic = values_counts(rows)
  current_uncertainty = my_index(rows)

  for col in rows.columns:
    values = value_counting(rows[col]) # find distinct values in the column
    
    for val in values:
      question = Split_Criteria(col, val) # set the current criteria 
      #print ("Main Q:  ", question)
      true_rows, false_rows = partition(rows, question)
      if len(true_rows) == 0 or len (false_rows) == 0:
        continue
      #print ("pos: ", true_rows)
      #print("---------------------------")
      #print ("neg:", false_rows)
      current_gain_calculation = info_gain(true_rows, false_rows, current_uncertainty)

      if current_gain_calculation > best_ID3:
        best_ID3, best_feature = current_gain_calculation, question
    
    return best_ID3, best_feature

# Not used
def create_dict(indexes, values):
  entry = {}
  pair = {}
  for idx in indexes:            
    if is_numeric(idx):
      #print("number ", idx, " value ", values[idx])
      pair.update( {idx: values[idx]} )
    else:
      #print("idx = ", idx, "pair = ", pair)
      entry.update( {idx: pair} )  
  return entry

def mylabel_counts(datarows):
  entry = {}
  for col in range (1, 3):#, len(datarows.columns)):
    cts = datarows[col].value_counts()    
    pair = {}
    #print (cts.index, cts.values)
    for idx in cts.index:            
      if is_numeric(idx):
        #print (cts.index, cts[idx] )
        pair.update( {idx: cts[idx]} )
      else:
        #print("idx = ", idx, "pair = ", pair)
        entry.update( {idx: pair} )  
  return entry

def label_counts(labels_rows):
  counts = {}
  for row in labels_rows:
    label = row[-1]
    if label not in counts:
        counts[label] = 0 #add new label
    counts[label] += 1  #increment
  return counts

"""##Experimental Evaluation"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, roc_auc_score
# %matplotlib inline

#df = pd.read_excel('kaggle.xlsx', sheet_name='dataset')

"""#####Confusion Matrix, Precision, Recall, F1 Score, Accuracy Scores sourced from [Stack Abuse](https://stackabuse.com/decision-trees-in-python-with-scikit-learn/) </br>Sensitivity and Specificity sourced from [Statifner](https://statinfer.com/204-4-2-calculating-sensitivity-and-specificity-in-python/)"""

X = df.drop('Result', axis=1)
y = df['Result']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)
classifier = DecisionTreeClassifier()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(classification_report(y_test, y_pred))

"""##### ROC Curve and AUC sourced from [ML Mastery site](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/)"""

cm1 = confusion_matrix(y_test, y_pred)
print('Confusion Matrix : \n', cm1)

total1=sum(sum(cm1))
#####from confusion matrix calculate accuracy
accuracy1=(cm1[0,0]+cm1[1,1])/total1
print ('Accuracy : ', accuracy1)

sensitivity1 = cm1[0,0]/(cm1[0,0]+cm1[0,1])
print('Sensitivity : ', sensitivity1 )

specificity1 = cm1[1,1]/(cm1[1,0]+cm1[1,1])
print('Specificity : ', specificity1)

# roc curve and auc

# split into train/test sets
trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.2, random_state=2)
# generate a no skill prediction (majority class)
ns_probs = [0 for _ in range(len(testy))]
# fit a model
#model = LogisticRegression(solver='lbfgs')
model = DecisionTreeClassifier()
model.fit(trainX, trainy)
# predict probabilities
lr_probs = model.predict_proba(testX)
# keep probabilities for the positive outcome only
lr_probs = lr_probs[:, 1]
# calculate scores
ns_auc = roc_auc_score(testy, ns_probs)
lr_auc = roc_auc_score(testy, lr_probs)
# summarize scores
print('No Skill: ROC AUC=%.3f' % (ns_auc))
print('Decision Tree: ROC AUC=%.3f' % (lr_auc))
# calculate roc curves
ns_fpr, ns_tpr, _ = roc_curve(testy, ns_probs)
lr_fpr, lr_tpr, _ = roc_curve(testy, lr_probs)
# plot the roc curve for the model
plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')
plt.plot(lr_fpr, lr_tpr, marker='.', label='Decision Tree')
# axis labels
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
# show the legend
plt.legend()
# show the plot
plt.show()

